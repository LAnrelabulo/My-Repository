{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 7495.68408203125,
      "end_time": 1620481449741.919
     }
    },
    "id": "evwMo2asrLt_",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "path = \"bigdata-exam-environment/Files/movies.jsonl\"\n",
    "movies_df = spark.read.json(path).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YkrETYaBrLt_"
   },
   "source": [
    "The type of our dataset object is DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 35.862060546875,
      "end_time": 1573665101742.127
     }
    },
    "id": "tr6Ng12YI7Du"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(movies_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdB-a8xnI7Du"
   },
   "source": [
    "Print the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 251.81103515625,
      "end_time": 1573665103317.247
     }
    },
    "id": "0lV6WdLQI7Du"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- actors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- birth: string (nullable = true)\n",
      " |    |    |-- death: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- votes: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, avg, split\n",
    "from pyspark.sql.types import IntegerType, NumericType, decimal, DecimalType, DoubleType\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", \"i.birth\", \"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "datainteger = data.select(data[\"year\"].cast(IntegerType()), data[\"birth\"].cast(IntegerType()), \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "minage = datainteger.withColumn(\"age\",  datainteger[\"year\"] - datainteger[\"birth\"]).groupBy(\"name\", \"year\").min(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------+\n",
      "|              name|year|min(age)|\n",
      "+------------------+----+--------+\n",
      "|       Corbyn Lowe|2013|      15|\n",
      "|       Fynn Henkel|2011|      15|\n",
      "|   Jonathan Dümcke|2006|      15|\n",
      "|       Nick Fowler|2006|      15|\n",
      "|         Neil Hope|1987|      15|\n",
      "|      Gary Coleman|1983|      15|\n",
      "|     Philip McKeon|1979|      15|\n",
      "|Sergei Krupennikov|1978|      15|\n",
      "|  Dmitri Krechetov|1975|      15|\n",
      "|    Shawn Campbell|1973|      15|\n",
      "|     Roderick Shaw|1973|      15|\n",
      "|  Simon Gipps-Kent|1973|      15|\n",
      "|     Keith Chegwin|1972|      15|\n",
      "|Manuel Padilla Jr.|1970|      15|\n",
      "|      Milos Vognic|1969|      15|\n",
      "| John David Carson|1967|      15|\n",
      "|Balázs Kosztolányi|1963|      15|\n",
      "|       Rusty Hamer|1962|      15|\n",
      "|        Tim Rooney|1962|      15|\n",
      "|     Gilles Payant|1962|      15|\n",
      "+------------------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minage.filter(minage[\"min(age)\"] == 15).orderBy(\"year\", ascending = False ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+\n",
      "|                   i|birth|year|\n",
      "+--------------------+-----+----+\n",
      "|{1919, 1988, Gabr...| 1919|1941|\n",
      "|{1910, 1979, Dick...| 1910|1941|\n",
      "|{1920, 1976, Bill...| 1920|1941|\n",
      "|{1920, 1999, Hunt...| 1920|1941|\n",
      "+--------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.filter(movies_df[\"name\"] == \"Mob Town\").select(explode(movies_df[\"actors\"]).alias(\"i\"), \"i.birth\", movies_df[\"year\"].cast(IntegerType())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          name|count|\n",
      "+--------------+-----+\n",
      "|     Mel Blanc| 1186|\n",
      "|   Jack Mercer|  635|\n",
      "|Michael Landon|  591|\n",
      "|  James Arness|  578|\n",
      "| Milburn Stone|  577|\n",
      "|  Raymond Burr|  499|\n",
      "|   Daws Butler|  493|\n",
      "|    Paul Frees|  385|\n",
      "|  Lorne Greene|  380|\n",
      "|   Dan Blocker|  364|\n",
      "|  Jackson Beck|  359|\n",
      "|   Don Messick|  359|\n",
      "|Richard Crenna|  358|\n",
      "|Edgar Buchanan|  358|\n",
      "|Walter Brennan|  345|\n",
      "|  Peter Thomas|  334|\n",
      "| Dennis Weaver|  320|\n",
      "|  Ozzie Nelson|  318|\n",
      "|  Ricky Nelson|  315|\n",
      "|  David Nelson|  313|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\").groupBy(\"i.name\").count().sort(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|year|sum(votes)|\n",
      "+----+----------+\n",
      "|1957|   1673009|\n",
      "|1954|   1586085|\n",
      "|1960|   1539885|\n",
      "|1959|   1525685|\n",
      "|1962|   1372253|\n",
      "|1968|   1239030|\n",
      "|1939|   1165867|\n",
      "|1964|   1138673|\n",
      "|1955|   1128751|\n",
      "|1958|   1094661|\n",
      "|1941|   1081774|\n",
      "|1953|   1081183|\n",
      "|1963|   1074507|\n",
      "|1950|   1043050|\n",
      "|1946|   1014856|\n",
      "|1961|    998506|\n",
      "|1940|    978235|\n",
      "|1942|    972899|\n",
      "|1951|    931534|\n",
      "|1956|    872253|\n",
      "+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(\"year\", movies_df[\"votes\"].cast(IntegerType())).groupBy(\"year\").sum(\"votes\").orderBy(\"sum(votes)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|      avg(rating)|\n",
      "+--------------------+-----------------+\n",
      "|       John H. Moore|             10.0|\n",
      "|      Charles Cullum|             10.0|\n",
      "|     Walter Kiaulehn|             10.0|\n",
      "|     Willem Holsboer|             10.0|\n",
      "|    Kurt Wehofschitz|              9.9|\n",
      "|    Erwin Scherschel|              9.8|\n",
      "|       Ottokar Runze|              9.8|\n",
      "|         John Wesley|              9.7|\n",
      "|        Eugen Verber|              9.7|\n",
      "|          Karl Luley|              9.6|\n",
      "|      Walter Tarrach|              9.6|\n",
      "|       Allen Sferios|              9.6|\n",
      "|   Friedrich Siemers|              9.6|\n",
      "|     Herbert Johnson|              9.6|\n",
      "|Hans Müller-Weste...|              9.6|\n",
      "|         Otto Collin|              9.6|\n",
      "|        Paul Günther|              9.6|\n",
      "|     Bernd M. Bausch|              9.6|\n",
      "|      Wolfgang Spier|             9.55|\n",
      "|     Beppo Schwaiger|9.533333333333333|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", movies_df[\"rating\"].cast(DoubleType())).groupBy(\"i.name\").avg(\"rating\").orderBy(\"avg(rating)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating= movies_df.select(avg(movies_df[\"rating\"].cast(DoubleType()))).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.673361642793781"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Genre= movies_df.select.select(movies_df[\"rating\"].cast(DoubleType()), \"genres\").groupby(\"genres\").avg(\"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       avg(rating)|\n",
      "+--------------------+------------------+\n",
      "|Action,Adventure,...| 5.771428571428572|\n",
      "|        Comedy,Sport| 6.043181818181819|\n",
      "| Adult,Horror,Sci-Fi|               6.9|\n",
      "|  Action,War,Western|              5.75|\n",
      "|  Crime,Horror,Short|               6.9|\n",
      "|Drama,Romance,Tal...|               5.3|\n",
      "|  Action,Adult,Short|               4.5|\n",
      "|Fantasy,Horror,Mu...|               7.6|\n",
      "| Music,Musical,Short|              6.85|\n",
      "|Adventure,Family,...| 6.924489795918366|\n",
      "|Comedy,Drama,Western| 6.288461538461538|\n",
      "| Documentary,Western|6.8999999999999995|\n",
      "|Game-Show,Reality-TV|              8.25|\n",
      "|Comedy,Family,His...|               7.0|\n",
      "|Film-Noir,Horror,...|              6.35|\n",
      "|   Music,Short,Sport|               5.9|\n",
      "|Fantasy,Mystery,T...|               7.1|\n",
      "|Fantasy,Sci-Fi,Th...|               6.6|\n",
      "|   Documentary,Sport| 6.915789473684211|\n",
      "|Comedy,Musical,Sc...|             5.325|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Genre.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|              genres|       avg(rating)|\n",
      "+--------------------+------------------+\n",
      "| Adult,Horror,Sci-Fi|               6.9|\n",
      "|  Crime,Horror,Short|               6.9|\n",
      "|Fantasy,Horror,Mu...|               7.6|\n",
      "| Music,Musical,Short|              6.85|\n",
      "|Adventure,Family,...| 6.924489795918366|\n",
      "| Documentary,Western|6.8999999999999995|\n",
      "|Game-Show,Reality-TV|              8.25|\n",
      "|Comedy,Family,His...|               7.0|\n",
      "|Fantasy,Mystery,T...|               7.1|\n",
      "|   Documentary,Sport| 6.915789473684211|\n",
      "|Action,Animation,...| 7.066666666666666|\n",
      "|Film-Noir,Mystery...| 7.166666666666667|\n",
      "|Documentary,Horro...|               6.8|\n",
      "|       Comedy,Family| 7.719479218828239|\n",
      "|    Animation,Comedy| 7.154166666666669|\n",
      "|Biography,Documen...| 6.940909090909091|\n",
      "|Drama,Fantasy,Fil...|               7.2|\n",
      "|               Crime| 6.713854351687388|\n",
      "|Biography,Drama,M...| 6.736363636363635|\n",
      "|Musical,Romance,T...|              6.85|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Genre.filter(Genre[\"avg(rating)\"] > average_rating).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|rating|        avg(votes)|\n",
      "+------+------------------+\n",
      "|     1|            449.72|\n",
      "|     6|294.60998965794613|\n",
      "|     3|154.43396226415095|\n",
      "|     5|176.38442840306422|\n",
      "|     9|165.26829268292684|\n",
      "|     4|124.35920889987639|\n",
      "|     8|1788.9719594594594|\n",
      "|     7| 763.4944402324994|\n",
      "|    10|               5.5|\n",
      "|     2|  168.562874251497|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(movies_df[\"rating\"].cast(IntegerType()), movies_df[\"votes\"].cast(IntegerType())).groupby(\"rating\").avg(\"votes\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22737"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\").select(\"name\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_actor = movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", \"name\")\n",
    "movie_actor.filter(movie_actor[\"i.name\"] == \"Mickey Rooney\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------+\n",
      "|             name|avg(rating)|\n",
      "+-----------------+-----------+\n",
      "|  Willem Holsboer|       10.0|\n",
      "|  Walter Kiaulehn|       10.0|\n",
      "|    John H. Moore|       10.0|\n",
      "|   Charles Cullum|       10.0|\n",
      "|     Zorko Rajcic|        9.0|\n",
      "|     Zale Kessler|        9.0|\n",
      "|   Wolfgang Spier|        9.0|\n",
      "|   Willi Hoffmann|        9.0|\n",
      "|Werner Hessenland|        9.0|\n",
      "|     Werner Dahms|        9.0|\n",
      "|   Walter Tarrach|        9.0|\n",
      "|      Walter Hoor|        9.0|\n",
      "|   Vukan Dimevski|        9.0|\n",
      "|      Tommy Vance|        9.0|\n",
      "|       Tom Snyder|        9.0|\n",
      "|       Todd Davis|        9.0|\n",
      "|       Tito Vuolo|        9.0|\n",
      "|    Timmy Everett|        9.0|\n",
      "|        Tim Meats|        9.0|\n",
      "|     Tibor Badari|        9.0|\n",
      "+-----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", movies_df[\"rating\"].cast(IntegerType())).groupBy(\"i.name\").avg(\"rating\").orderBy([\"avg(rating)\", \"name\"], ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RulamP9RI7Du"
   },
   "source": [
    "Print one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 3283.30908203125,
      "end_time": 1573665107643.345
     }
    },
    "id": "KJ7JYfnZI7Du"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(customer=Row(first_name='Preston', last_name='Landry'), date='2018-2-4', items=[Row(price=1.53, product='fan', quantity=5), Row(price=1.33, product='computer screen', quantity=6), Row(price=1.06, product='kettle', quantity=6), Row(price=1.96, product='stuffed animal', quantity=3), Row(price=1.09, product='the book', quantity=7), Row(price=1.42, product='headphones', quantity=9), Row(price=1.67, product='whiskey bottle', quantity=3)], order_id=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.limit(1).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJOQJZwlI7Du"
   },
   "source": [
    "You can access the underlying RDD object and use any functions you learned for Spark RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 17329.39501953125,
      "end_time": 1573665345486.969
     }
    },
    "id": "v8Nw_5rmI7Dv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.rdd.filter(lambda ordr: ordr.customer.last_name == \"Landry\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df_interger = movies_df.select(split(\"genres\", \",\",3).alias(\"genre\"), movies_df[\"rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|      genre|       avg(rating)|\n",
      "+-----------+------------------+\n",
      "|      Crime| 6.402219922867086|\n",
      "|    Romance| 5.946172712017555|\n",
      "|   Thriller| 5.952978056426332|\n",
      "|  Adventure| 5.994167735915083|\n",
      "|      Drama| 6.244049980166601|\n",
      "|        War| 6.318181818181818|\n",
      "|Documentary| 6.527777777777778|\n",
      "| Reality-TV| 6.304347826086956|\n",
      "|     Family| 6.673382705292965|\n",
      "|    Fantasy|   6.5446735395189|\n",
      "|  Game-Show| 5.904761904761905|\n",
      "|      Adult| 5.486725663716814|\n",
      "|    History| 6.352576039726878|\n",
      "|    Mystery| 6.426814268142682|\n",
      "|    Musical| 5.833333333333333|\n",
      "|  Animation|   6.1298755186722|\n",
      "|      Music| 6.115518096182449|\n",
      "|  Film-Noir|6.1834239130434785|\n",
      "|      Short| 5.730222613507735|\n",
      "|     Horror| 5.859930615784909|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df_interger.select(explode(\"i\").alias(\"genre\"), \"rating\").groupBy(\"genre\").avg(\"rating\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.229230574217264"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg _df_interger.groupBy().avg(\"rating\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|split(genres, ,, -1)|rating|\n",
      "+--------------------+------+\n",
      "|          [Thriller]|   3.8|\n",
      "|[Action, Adventur...|   7.9|\n",
      "|[Comedy, Crime, D...|   7.9|\n",
      "|[Animation, Famil...|   6.2|\n",
      "|            [Comedy]|   7.1|\n",
      "|         [Adventure]|   5.8|\n",
      "|[Drama, Family, R...|   8.9|\n",
      "|             [Drama]|   6.1|\n",
      "|[Adventure, Comed...|   7.6|\n",
      "|[Action, Drama, R...|   5.4|\n",
      "|[Animation, Comed...|   7.1|\n",
      "|    [Drama, Romance]|   5.7|\n",
      "|   [Comedy, Musical]|   5.3|\n",
      "|            [Comedy]|   7.4|\n",
      "|            [Comedy]|   4.5|\n",
      "|            [Comedy]|   6.4|\n",
      "|[Adventure, Crime...|   5.2|\n",
      "|[Documentary, Short]|   6.3|\n",
      "|[Action, Adventur...|   7.8|\n",
      "|  [Animation, Short]|   6.9|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(split(\"genres\", \",\"), \"rating\").(explode(\"split(genres, ,, -1)\").alias(\"genre\"), movies_df[\"rating\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = movies_df_interger.groupBy().avg(\"rating\").collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_mick = movies_df.filter(array_contains(movies_df[\"actors\"][\"name\"], \"Mickey Rooney\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_mick.filter(movie_mick[\"name\"] != \"Mickey Rooney\").select(\"name\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 col|\n",
      "+--------------------+\n",
      "|{1880, 1954, Edwa...|\n",
      "|{1878, 1947, Harr...|\n",
      "|{1909, 2010, Geor...|\n",
      "|{1877, 1959, Russ...|\n",
      "|{1904, 1974, John...|\n",
      "|{1910, 1975, Bob ...|\n",
      "|{1901, 1976, Fuzz...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.filter(movies_df[\"name\"] == \"Desperate Trails\").select(explode(\"actors\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "movienn = movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", \"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                name|count|\n",
      "+--------------------+-----+\n",
      "|        Episode #1.1|   78|\n",
      "|        Episode #1.2|   63|\n",
      "|               Pilot|   63|\n",
      "|            The Trap|   56|\n",
      "|        Episode #1.3|   46|\n",
      "|        The Stranger|   44|\n",
      "|         The Hostage|   39|\n",
      "|        The Fugitive|   39|\n",
      "|Where There's a Will|   38|\n",
      "|         The Witness|   36|\n",
      "|      Double Trouble|   34|\n",
      "|             Othello|   34|\n",
      "|              Hamlet|   32|\n",
      "|        Episode #1.4|   31|\n",
      "|          The Search|   31|\n",
      "|The Three Musketeers|   31|\n",
      "|            The Hero|   31|\n",
      "|        The Prisoner|   30|\n",
      "|          Homecoming|   30|\n",
      "|             The Gun|   29|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movienn.groupBy(movies_df[\"name\"]).count().orderBy(\"count\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "micandwynn = movies_df.filter(array_contains(movies_df[\"actors\"][\"name\"], \"Mickey Rooney\")).filter(array_contains(movies_df[\"actors\"][\"name\"], \"Keenan Wynn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micandwynn.select(\"name\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gHxD8vNI7Dv"
   },
   "source": [
    "### 1.2. Dataframe Operations\n",
    "We perform some queries using operations on Dataframes ([Here](https://spark.apache.org/docs/2.3.0/sql-programming-guide.html#untyped-dataset-operations-aka-dataframe-operations) is a guide on DF Operations with a link to the [API Documentation](https://spark.apache.org/docs/2.3.0/api/python/pyspark.sql.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ae6QeA9YI7Dv"
   },
   "source": [
    "We can select columns and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 252.5771484375,
      "end_time": 1573665989686.293
     }
    },
    "id": "pxG1k0FKI7Dv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|   Preston|   Landry|\n",
      "|    Jamari|Dominguez|\n",
      "|   Brendon|  Sicilia|\n",
      "|    Armani|   Ardeni|\n",
      "|    Jamari|     Miao|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.select(\"customer.first_name\", \"customer.last_name\").limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbfzPHCmI7Dv"
   },
   "source": [
    "As you can see we can navigate to the nested items with the dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2263.60888671875,
      "end_time": 1573665774856.528
     }
    },
    "id": "CY7FDKGcI7Dv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1960"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.filter(orders_df[\"customer.last_name\"] == \"Landry\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5V7_pSRI7Dw"
   },
   "source": [
    "How about nested arrays?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 251.12890625,
      "end_time": 1573666229796.764
     }
    },
    "id": "nL8TxoZRI7Dw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|order_id|               items|\n",
      "+--------+--------------------+\n",
      "|       0|[{1.53, fan, 5}, ...|\n",
      "|       1|[{1.61, fan, 7}, ...|\n",
      "|       2|[{1.41, the book,...|\n",
      "|       3|[{1.05, computer ...|\n",
      "|       4|[{1.92, headphone...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.select(\"order_id\", \"items\").orderBy(\"order_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kN7ySTnGI7Dw"
   },
   "source": [
    "Let us try to find orders of a fan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 239.119140625,
      "end_time": 1573666737735.271
     }
    },
    "id": "PpX6QYOaI7Dw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------+\n",
      "|            customer|    date|               items|order_id|\n",
      "+--------------------+--------+--------------------+--------+\n",
      "|   {Preston, Landry}|2018-2-4|[{1.53, fan, 5}, ...|       0|\n",
      "| {Jamari, Dominguez}|2016-1-8|[{1.61, fan, 7}, ...|       1|\n",
      "|  {Brendon, Sicilia}|2016-6-6|[{1.41, the book,...|       2|\n",
      "|      {Jamari, Miao}|2016-4-6|[{1.92, headphone...|       4|\n",
      "|   {Jensen, Balster}|2017-4-9|[{1.87, fan, 5}, ...|       5|\n",
      "|    {Carlo, Marinko}|2017-1-3|[{1.65, whiskey b...|       8|\n",
      "|      {Ashtyn, Dahl}|2016-2-7|[{1.85, whiskey b...|       9|\n",
      "|  {Aydin, Mc namara}|2018-3-4|[{1.35, kettle, 7...|      12|\n",
      "|      {Briana, Egan}|2018-6-1|[{1.19, toaster, ...|      14|\n",
      "|  {Niko, Berenguier}|2016-1-1|[{1.15, fan, 10},...|      16|\n",
      "|{Kristen, Bridgeman}|2018-3-4|[{1.92, mouse tra...|      17|\n",
      "|      {Averi, Drago}|2018-4-4|[{1.3, whiskey bo...|      18|\n",
      "|     {Kendra, Horah}|2017-3-3|[{1.65, notebook,...|      21|\n",
      "|{Janiyah, Galatioto}|2018-4-6|[{1.33, headphone...|      23|\n",
      "|    {Skylar, Landry}|2017-2-6|[{1.31, notebook,...|      25|\n",
      "| {Rhett, Srivastava}|2018-5-8|[{1.1, whiskey bo...|      26|\n",
      "|   {Elaine, Schuler}|2016-2-6|[{1.06, stuffed a...|      29|\n",
      "|     {Cindy, Landry}|2017-6-4|[{1.98, headphone...|      30|\n",
      "|    {Deanna, Ardeni}|2017-4-9|[{1.52, toaster, ...|      32|\n",
      "|   {Yareli, Delossa}|2017-2-9|[{1.33, fan, 1}, ...|      33|\n",
      "+--------------------+--------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.filter(array_contains(orders_df[\"items.product\"], \"fan\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders_df.filter(array_contains(\"items.product\", \"fan\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGq1NjntI7Dw"
   },
   "source": [
    "The above code doesn't work! Use ```array contains``` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 251.64599609375,
      "end_time": 1573666726393.938
     }
    },
    "id": "jLASULZuI7Dw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32778"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import array_contains\n",
    "\n",
    "orders_df.filter(array_contains(\"items.product\", \"fan\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAuJJGGRI7Dx"
   },
   "source": [
    "Let us try to unnest the data.\n",
    "\n",
    "Unnest the products with explode.\n",
    "\n",
    "Explode will generate as many rows as there are elements in the array and match them to other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1255.80712890625,
      "end_time": 1573666787807.612
     }
    },
    "id": "JzGEFcZoI7Dx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+\n",
      "|                   i|price|order_id|\n",
      "+--------------------+-----+--------+\n",
      "|      {1.53, fan, 5}| 1.53|       0|\n",
      "|{1.33, computer s...| 1.33|       0|\n",
      "|   {1.06, kettle, 6}| 1.06|       0|\n",
      "|{1.96, stuffed an...| 1.96|       0|\n",
      "| {1.09, the book, 7}| 1.09|       0|\n",
      "+--------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "orders_df.select(explode(\"items\").alias(\"i\"), \"i.price\", \"order_id\").orderBy(\"order_id\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------+\n",
      "|                   i|        product|order_id|\n",
      "+--------------------+---------------+--------+\n",
      "|{1.91, whiskey bo...| whiskey bottle|   99999|\n",
      "|{1.57, mouse trap...|     mouse trap|   99999|\n",
      "|  {1.02, toaster, 8}|        toaster|   99999|\n",
      "|  {1.81, toaster, 7}|        toaster|   99999|\n",
      "|{1.76, computer s...|computer screen|   99999|\n",
      "|{1.55, headphones...|     headphones|   99998|\n",
      "|      {1.16, fan, 7}|            fan|   99998|\n",
      "|{1.27, headphones...|     headphones|   99998|\n",
      "|   {1.26, kettle, 7}|         kettle|   99998|\n",
      "| {1.4, the book, 10}|       the book|   99998|\n",
      "|{1.62, whiskey bo...| whiskey bottle|   99997|\n",
      "|  {1.37, toaster, 2}|        toaster|   99997|\n",
      "| {1.73, notebook, 8}|       notebook|   99997|\n",
      "|{1.1, headphones, 2}|     headphones|   99997|\n",
      "|  {1.92, toaster, 4}|        toaster|   99997|\n",
      "|{1.03, computer s...|computer screen|   99996|\n",
      "|{1.7, stuffed ani...| stuffed animal|   99996|\n",
      "|      {1.99, fan, 7}|            fan|   99996|\n",
      "|{1.81, whiskey bo...| whiskey bottle|   99996|\n",
      "| {1.14, the book, 3}|       the book|   99996|\n",
      "+--------------------+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.select(explode(\"items\").alias(\"i\"), \"i.product\", \"order_id\").orderBy(\"order_id\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0zlLnp4I7Dx"
   },
   "source": [
    "Now we can use this table to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = orders_df.select(explode(\"items\").alias(\"i\"), \"i.product\", \"order_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+--------+\n",
      "|             i|product|order_id|\n",
      "+--------------+-------+--------+\n",
      "|{1.53, fan, 5}|    fan|       0|\n",
      "|{1.61, fan, 7}|    fan|       1|\n",
      "| {1.1, fan, 7}|    fan|       2|\n",
      "|{1.15, fan, 8}|    fan|       2|\n",
      "|{1.44, fan, 2}|    fan|       4|\n",
      "+--------------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df.filter(exploded_df[\"product\"] == \"fan\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 746.837158203125,
      "end_time": 1573667003917.751
     }
    },
    "id": "cdGtZJR4I7Dx"
   },
   "outputs": [],
   "source": [
    "exploded_df = orders_df.select(explode(\"items\").alias(\"i\"), \"i.product\", \"order_id\")\n",
    "exploded_df.filter(exploded_df[\"product\"] == \"fan\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3MFtKmEI7Dx"
   },
   "source": [
    "You might have tried to access the i.product column directly using a ```.filter``` right after the ```.select```. That, however, does not work, because the column is not available to ```orders_df``` when creating a clause like ```(orders_df[\"i.product\"] == \"fan\")```. A possible workaround when using Dataframe operations is that of using a string clause in ```.filter```, so that the product column will be resolved after it has been added with the ```.select```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 247.906005859375,
      "end_time": 1573667777707.59
     }
    },
    "id": "RXzDgj5AI7Dy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "orders_df.select(explode(\"items\").alias(\"i\"), \"i.product\", \"order_id\").filter(\"product = 'fan'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smURKnCRI7Dy"
   },
   "source": [
    "Project the nested columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+---------------+--------+----------+---------+\n",
      "|order_id|price|        product|quantity|first_name|last_name|\n",
      "+--------+-----+---------------+--------+----------+---------+\n",
      "|       0| 1.53|            fan|       5|   Preston|   Landry|\n",
      "|       0| 1.33|computer screen|       6|   Preston|   Landry|\n",
      "|       0| 1.06|         kettle|       6|   Preston|   Landry|\n",
      "|       0| 1.96| stuffed animal|       3|   Preston|   Landry|\n",
      "|       0| 1.09|       the book|       7|   Preston|   Landry|\n",
      "+--------+-----+---------------+--------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.select(explode(\"items\").alias(\"i\"), \"*\").select(\"order_id\", \"i.*\", \"customer.*\").limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 269.365966796875,
      "end_time": 1573669285846.051
     }
    },
    "id": "KwxIIJbNI7Dy"
   },
   "outputs": [],
   "source": [
    "orders_df.select(explode(\"items\").alias(\"i\"), \"*\").select(\n",
    "    \"order_id\", \"customer.*\", \"date\", \"i.*\").limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.select(explode(\"=\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxdSOAELI7Dy"
   },
   "source": [
    "### 1.3 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbaeoySMI7Dy"
   },
   "source": [
    "1) Find the average quantity at which each product is purchased. Only show the top 10 products by quantity. (Hint: you may need to import the function ```desc``` from ```pyspark.sql.functions``` to define descending order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 4287.89892578125,
      "end_time": 1573675535490.617
     }
    },
    "id": "y2-nJF5pI7Dy"
   },
   "outputs": [],
   "source": [
    "exploded_table =orders_df.select(explode(\"items\").alias(\"i\"), \"*\").select(\"i.*\", \"customer.*\", \"order_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------+----------+---------+--------+\n",
      "|price|        product|quantity|first_name|last_name|order_id|\n",
      "+-----+---------------+--------+----------+---------+--------+\n",
      "| 1.53|            fan|       5|   Preston|   Landry|       0|\n",
      "| 1.33|computer screen|       6|   Preston|   Landry|       0|\n",
      "| 1.06|         kettle|       6|   Preston|   Landry|       0|\n",
      "| 1.96| stuffed animal|       3|   Preston|   Landry|       0|\n",
      "| 1.09|       the book|       7|   Preston|   Landry|       0|\n",
      "+-----+---------------+--------+----------+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_table.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n",
      "|        product|    avg(quantity)|\n",
      "+---------------+-----------------+\n",
      "|       the book|5.514178678641427|\n",
      "|     mouse trap|5.503895651308093|\n",
      "|computer screen|5.504839685420448|\n",
      "| whiskey bottle|5.475555222463714|\n",
      "|        toaster|5.515549016184942|\n",
      "| stuffed animal|5.470854598218753|\n",
      "|         kettle|5.512053325314489|\n",
      "|            fan|5.496342868593758|\n",
      "|     headphones|5.485920795060985|\n",
      "|       notebook|5.483182341458532|\n",
      "+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_table.groupBy(\"product\").avg(\"quantity\").limit(100).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy3TVhpII7Dy"
   },
   "source": [
    "2) Find the most expensive order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 2290.953125,
      "end_time": 1573669705281.358
     }
    },
    "id": "LrY_mSnoI7Dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|order_id|        sum(price)|\n",
      "+--------+------------------+\n",
      "|   98235|             13.21|\n",
      "|   36484|13.170000000000002|\n",
      "|   11409|             12.97|\n",
      "|   74460|12.870000000000001|\n",
      "|    9913|             12.86|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_table.groupBy(\"order_id\").sum(\"price\").orderBy(\"sum(price)\", ascending = False).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afpPBhRBrLuR"
   },
   "source": [
    "## 2. Spark SQL\n",
    "\n",
    "Spark SQL allows the users to formulate their queries using SQL. The requirement is the use of Dataframes, which as said before are similar to relational tables. In addition to a familiar interface, writing queries in SQL might provide better performance than RDDs, inheriting efficiency from the Dataframe operations, while also performing automatic optimization of queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsTLU8ml2ORG"
   },
   "source": [
    "But what if we are interested not only in the number of dates, but the actual\n",
    "dates themselves? Luckily Spark Dataframes / Spark SQL do provide us with methods to preserve the original information of the date list. If now we would like to know for each customer, on which dates they placed an order, we shall use <font face=\"courier\">collect_set</font> method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 1418.15087890625,
      "end_time": 1620478080466.68
     }
    },
    "id": "h1oGXmWt3gss"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|first_name|           last_name|   collect_set(date)|\n",
      "+----------+--------------------+--------------------+\n",
      "|     Abbie|                Egan|[2018-4-8, 2016-3...|\n",
      "|  Abigayle|           Mc namara|[2016-4-2, 2017-6-9]|\n",
      "|   Adalynn|              Ardeni|[2018-2-2, 2018-6...|\n",
      "|      Aden|          Rosenbloom|         [2016-3-10]|\n",
      "|    Adonis|              Badash|          [2017-6-8]|\n",
      "|   Agustin|          Srivastava|         [2018-4-10]|\n",
      "|     Aiden|             Suchoff|          [2018-2-8]|\n",
      "|    Aiyana|              Landry|          [2018-2-3]|\n",
      "|    Alaina|              Gruber|[2016-3-1, 2018-5-1]|\n",
      "|    Alayna|               Mayer|         [2016-3-10]|\n",
      "|Alexandria|         Butterfield|[2018-5-3, 2017-4...|\n",
      "|Alexzander|              Landry|[2017-1-3, 2017-6-3]|\n",
      "|     Alice|             Balster|[2018-4-4, 2017-4-7]|\n",
      "|     Allan|                  Po|[2016-1-9, 2016-5...|\n",
      "|     Allie|          Berenguier|[2016-2-1, 2017-1...|\n",
      "|    Alyvia|              Ardeni|          [2017-4-8]|\n",
      "|     Amari|           Bridgeman|[2017-3-8, 2018-1-7]|\n",
      "|     Amiah|Fernandez cifuentes |[2016-1-8, 2017-1...|\n",
      "|  Anderson|              Zapata|          [2016-5-7]|\n",
      "|    Andres|                  Mo|          [2017-6-2]|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "orders_df.groupBy(\"customer.first_name\", \"customer.last_name\").agg(collect_set(\"date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 10117.97900390625,
      "end_time": 1620478640139.884
     }
    },
    "id": "aJW1JpzQ3lEV"
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select customer.first_name, customer.last_name, collect_set(\"date\") from orders group by customer.first_name, customer.last_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2rTR-O78gy3"
   },
   "source": [
    "For some other cases where we want to preserve all the entries rather than the de-duplicated ones, we can use  <font face=\"courier\">collect_list</font> method. For example, for each date we want to record the first and last names of customers. Since two customers might share the same last name, we need to collect all of them. The query should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 12271.528076171875,
      "end_time": 1620480910312.875
     }
    },
    "id": "X_PB-uAH9I5M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------+\n",
      "|     date|collect_list(customer.last_name)|\n",
      "+---------+--------------------------------+\n",
      "| 2017-4-8|            [Egan, Gruber, Le...|\n",
      "| 2016-2-5|            [Dahl, Findley, M...|\n",
      "| 2016-1-1|            [Suchoff, Lowe, D...|\n",
      "| 2018-2-6|            [Gottardo, Po, Go...|\n",
      "| 2018-1-7|            [Macmahon, Hirsch...|\n",
      "| 2016-6-7|            [Horah, Whitla, H...|\n",
      "|2018-5-10|            [Gruber, Drago, S...|\n",
      "| 2017-5-4|            [Srivastava, Ho-s...|\n",
      "| 2018-4-7|            [Drago, Mayer, La...|\n",
      "|2018-6-10|            [Badash, Decaro, ...|\n",
      "| 2017-3-3|            [Badash, Marinko,...|\n",
      "| 2017-3-5|            [Rosenbloom, Bals...|\n",
      "| 2017-6-4|            [Whitla, Egan, Lo...|\n",
      "| 2018-6-3|            [Cerda, Berenguie...|\n",
      "| 2018-1-6|            [Zapata, Miao, Ne...|\n",
      "| 2016-4-9|            [Badash, Dahlsted...|\n",
      "| 2016-1-5|            [Suchoff, Srivast...|\n",
      "|2018-1-10|            [Srivastava, Domi...|\n",
      "| 2017-1-5|            [Dower, Zapata, M...|\n",
      "| 2018-1-4|            [Dower, Miao, Mc ...|\n",
      "+---------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "orders_df.groupBy(\"date\").agg(collect_list(\"customer.last_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 30449.055908203125,
      "end_time": 1620481513099.958
     }
    },
    "colab": {
     "referenced_widgets": [
      "a2f4e8e80a2e424ba0e552e89b16a8a7",
      "2b9d668dbcfa4a639a140d117b5e3902"
     ]
    },
    "id": "z7DSOsKC9dmF",
    "outputId": "eae40ebd-63f9-4ec1-9742-f1bb391d1071"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f4e8e80a2e424ba0e552e89b16a8a7"
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b9d668dbcfa4a639a140d117b5e3902"
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%sql\n",
    "select \"date\", collect_list(customer.last_name) from orders group by \"date\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoJbUmwrQOmy"
   },
   "source": [
    "Now try it on yourself.\n",
    "\n",
    "For every order in 2016-1-1, return the list of products that appeared in that order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 90.6279296875,
      "end_time": 1620480224562.293
     }
    },
    "id": "GpWf6W_ZPg9-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------------+\n",
      "|order_id|collect_list(i.product)|\n",
      "+--------+-----------------------+\n",
      "|    8484|   [headphones, whis...|\n",
      "|   33209|   [notebook, the bo...|\n",
      "|   84024|   [computer screen,...|\n",
      "|   91703|   [notebook, stuffe...|\n",
      "|   28555|   [kettle, computer...|\n",
      "|    3120|   [whiskey bottle, ...|\n",
      "|   48533|               [kettle]|\n",
      "|   97472|   [toaster, the boo...|\n",
      "|    1280|   [whiskey bottle, ...|\n",
      "|   74743|           [mouse trap]|\n",
      "|   85793|   [whiskey bottle, ...|\n",
      "|   23754|   [the book, the bo...|\n",
      "|   24308|   [fan, fan, whiske...|\n",
      "|    9418|           [mouse trap]|\n",
      "|   98787|   [kettle, stuffed ...|\n",
      "|   35723|   [computer screen,...|\n",
      "|   47083|   [mouse trap, fan,...|\n",
      "|   58037|   [fan, kettle, mou...|\n",
      "|   66103|           [headphones]|\n",
      "|   94704|   [notebook, notebo...|\n",
      "+--------+-----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.filter(orders_df[\"date\"] == \"2016-1-1\").select(explode(\"items\").alias(\"i\"), \"date\", \"i.product\", \"order_id\").groupBy(\"order_id\").agg(collect_list(\"i.product\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ifIhGcEQmrT"
   },
   "source": [
    "For every product, return the set of dates at which it's purchased:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_status": {
     "execute_time": {
      "duration": 996.149169921875,
      "end_time": 1620480623060.309
     }
    },
    "id": "ZEmGI5GUPg9-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+\n",
      "|        product|  collect_list(date)|\n",
      "+---------------+--------------------+\n",
      "|       the book|[2018-2-4, 2016-6...|\n",
      "|     mouse trap|[2017-4-9, 2017-1...|\n",
      "|computer screen|[2018-2-4, 2018-2...|\n",
      "| whiskey bottle|[2018-2-4, 2016-1...|\n",
      "|        toaster|[2018-4-8, 2018-6...|\n",
      "| stuffed animal|[2018-2-4, 2016-6...|\n",
      "|         kettle|[2018-2-4, 2016-4...|\n",
      "|            fan|[2018-2-4, 2016-1...|\n",
      "|     headphones|[2018-2-4, 2016-6...|\n",
      "|       notebook|[2016-6-6, 2017-2...|\n",
      "+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_df.select(explode(\"items\").alias(\"i\"), \"i.product\", \"date\").groupBy(\"product\").agg(collect_list(\"date\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uboC94LIRThc"
   },
   "source": [
    "One of the drawbacks of the <font face=\"courier\">collect_set/collect_list</font> method is they only accept one column as the argument. Later we will see how we can create nestedness on pretty much everything after we get the hang of the mighty JSONiq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"confusion-2014-03-02/confusion-2014-03-02.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = spark.read.json(path).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|             choices|country|      date|    guess|              sample|   target|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "|[Maori, Mandarin,...|     AU|2013-08-19|Norwegian|48f9c924e0d98c959...|Norwegian|\n",
      "+--------------------+-------+----------+---------+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.limit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(dataset[\"guess\"]== dataset[\"target\"] ).filter(dataset[\"target\"] == \"Russian\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(dataset[\"guess\"]== dataset[\"target\"] ).filter(dataset[\"target\"] == \"Hindi\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(\"target\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(choices=['Albanian', 'Armenian', 'Farsi', 'Punjabi'], country='AU', date='2013-08-20', guess='Albanian', sample='00b85faa8b878a14f8781be334deb137', target='Albanian'),\n",
       " Row(choices=['Albanian', 'Assyrian', 'Hebrew', 'Spanish'], country='AU', date='2013-08-20', guess='Albanian', sample='13722ceed1eede7ba597ade9b4cb9807', target='Albanian'),\n",
       " Row(choices=['Albanian', 'Tagalog', 'Hindi', 'Urdu'], country='AU', date='2013-08-20', guess='Albanian', sample='00b85faa8b878a14f8781be334deb137', target='Albanian'),\n",
       " Row(choices=['Albanian', 'Tagalog', 'Khmer', 'Portuguese'], country='AU', date='2013-08-20', guess='Albanian', sample='13722ceed1eede7ba597ade9b4cb9807', target='Albanian'),\n",
       " Row(choices=['Albanian', 'Arabic', 'Assyrian', 'Indonesian'], country='AU', date='2013-08-20', guess='Albanian', sample='efcd813daec1c836d9f030b30caa07ce', target='Albanian')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.filter(dataset[\"target\"] == dataset[\"guess\"]).orderBy(\"target\", \"country\", \"date\").limit(5).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+\n",
      "|country|target|count|\n",
      "+-------+------+-----+\n",
      "+-------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.groupBy(\"country\", \"target\").count().filter(dataset[\"country\"] == \"NL\").filter(dataset[\"target\"] == \"Maltese\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = dataset.filter(dataset[\"target\"] == dataset[\"guess\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_first = dataset.filter(dataset[\"target\"] == dataset[\"guess\"]).filter(dataset[\"target\"] == dataset[\"choices\"][1]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34119880661784646"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_first/correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = dataset.rdd.map(lambda x: (x[\"target\"], x[\"target\"] == x[\"guess\"])).groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.mapValues(lambda x: list(x).count(True)/len(x)).sortBy(lambda x: x[1], ascending = False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Italian', 0.9609756097560975),\n",
       " ('German', 0.944954128440367),\n",
       " ('French', 0.9420289855072463),\n",
       " ('Spanish', 0.92),\n",
       " ('Japanese', 0.9090909090909091),\n",
       " ('Cantonese', 0.9065934065934066),\n",
       " ('Korean', 0.9023255813953488),\n",
       " ('Arabic', 0.8973214285714286),\n",
       " ('Mandarin', 0.8970588235294118),\n",
       " ('Russian', 0.8925233644859814),\n",
       " ('Hebrew', 0.8846153846153846),\n",
       " ('Vietnamese', 0.8594594594594595),\n",
       " ('Polish', 0.8394160583941606),\n",
       " ('Czech', 0.8231292517006803),\n",
       " ('Thai', 0.8076923076923077),\n",
       " ('Portuguese', 0.8041237113402062),\n",
       " ('Ukrainian', 0.8033707865168539),\n",
       " ('Norwegian', 0.8028846153846154),\n",
       " ('Romanian', 0.8020833333333334),\n",
       " ('Swedish', 0.8009950248756219),\n",
       " ('Slovak', 0.7965116279069767),\n",
       " ('Greek', 0.7906976744186046),\n",
       " ('Danish', 0.7428571428571429),\n",
       " ('Swahili', 0.7423312883435583),\n",
       " ('Dutch', 0.7384615384615385),\n",
       " ('Lao', 0.7352941176470589),\n",
       " ('Slovenian', 0.7348484848484849),\n",
       " ('Finnish', 0.7323943661971831),\n",
       " ('Tamil', 0.7310344827586207),\n",
       " ('Yiddish', 0.7310344827586207),\n",
       " ('Khmer', 0.7291666666666666),\n",
       " ('Gujarati', 0.7037037037037037),\n",
       " ('Tongan', 0.6911764705882353),\n",
       " ('Samoan', 0.6851851851851852),\n",
       " ('Tagalog', 0.6823529411764706),\n",
       " ('Latvian', 0.6818181818181818),\n",
       " ('Assyrian', 0.6808510638297872),\n",
       " ('Serbian', 0.675),\n",
       " ('Croatian', 0.6666666666666666),\n",
       " ('Kurdish', 0.6645569620253164),\n",
       " ('Macedonian', 0.6564885496183206),\n",
       " ('Punjabi', 0.6524822695035462),\n",
       " ('Somali', 0.6515151515151515),\n",
       " ('Bulgarian', 0.6513761467889908),\n",
       " ('Malayalam', 0.6495726495726496),\n",
       " ('Turkish', 0.6481481481481481),\n",
       " ('Bosnian', 0.6470588235294118),\n",
       " ('Burmese', 0.6461538461538462),\n",
       " ('Hungarian', 0.6446280991735537),\n",
       " ('Farsi', 0.6413043478260869),\n",
       " ('Estonian', 0.6370370370370371),\n",
       " ('Nepali', 0.6228070175438597),\n",
       " ('Albanian', 0.6165413533834586),\n",
       " ('Urdu', 0.6015625),\n",
       " ('Bangla', 0.5887096774193549),\n",
       " ('Armenian', 0.5813953488372093),\n",
       " ('Hindi', 0.5625),\n",
       " ('Tigrinya', 0.5566037735849056),\n",
       " ('Indonesian', 0.5428571428571428),\n",
       " ('Malay', 0.5340909090909091),\n",
       " ('Maltese', 0.504950495049505),\n",
       " ('Sinhalese', 0.5),\n",
       " ('Amharic', 0.47560975609756095),\n",
       " ('Maori', 0.463768115942029),\n",
       " ('Kannada', 0.45918367346938777),\n",
       " ('Fijian', 0.44),\n",
       " ('Dari', 0.43820224719101125),\n",
       " ('Dinka', 0.40229885057471265)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.select(\"actors\", \"genres\", \"name\", movies_df[\"votes\"].cast(IntegerType()), movies_df[\"year\"].cast(IntegerType()), movies_df[\"rating\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.filter(movies_df[\"year\"] == \"1991\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(name='Till Time Shall End', rating=10.0, votes=7)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(\"name\", \"rating\", \"votes\").orderBy(\"rating\", \"votes\",ascending = False).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieage = movies_df.filter(movies_df[\"name\"] == \"Mob Town\").select(explode(\"actors\").alias(\"i\"), \"i.birth\", \"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieageint = movieage.select(\"year\", movieage[\"birth\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|avg(age)|\n",
      "+--------+\n",
      "|   23.75|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movieageint.withColumn(\"age\",movieageint[\"year\"] - movieageint[\"birth\"]).select(avg(\"age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor in the most movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22737"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\").select(\"name\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|year|sum(votes)|\n",
      "+----+----------+\n",
      "|1957|   1673009|\n",
      "|1954|   1586085|\n",
      "|1960|   1539885|\n",
      "|1959|   1525685|\n",
      "|1962|   1372253|\n",
      "|1968|   1239030|\n",
      "|1939|   1165867|\n",
      "|1964|   1138673|\n",
      "|1955|   1128751|\n",
      "|1958|   1094661|\n",
      "|1941|   1081774|\n",
      "|1953|   1081183|\n",
      "|1963|   1074507|\n",
      "|1950|   1043050|\n",
      "|1946|   1014856|\n",
      "|1961|    998506|\n",
      "|1940|    978235|\n",
      "|1942|    972899|\n",
      "|1951|    931534|\n",
      "|1956|    872253|\n",
      "+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.groupBy(\"year\").sum(\"votes\").orderBy(\"sum(votes)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|      avg(rating)|\n",
      "+--------------------+-----------------+\n",
      "|     Walter Kiaulehn|             10.0|\n",
      "|      Charles Cullum|             10.0|\n",
      "|     Willem Holsboer|             10.0|\n",
      "|       John H. Moore|             10.0|\n",
      "|    Kurt Wehofschitz|              9.9|\n",
      "|       Ottokar Runze|              9.8|\n",
      "|    Erwin Scherschel|              9.8|\n",
      "|         John Wesley|              9.7|\n",
      "|        Eugen Verber|              9.7|\n",
      "|        Paul Günther|              9.6|\n",
      "|      Walter Tarrach|              9.6|\n",
      "|         Otto Collin|              9.6|\n",
      "|Hans Müller-Weste...|              9.6|\n",
      "|     Herbert Johnson|              9.6|\n",
      "|       Allen Sferios|              9.6|\n",
      "|          Karl Luley|              9.6|\n",
      "|   Friedrich Siemers|              9.6|\n",
      "|     Bernd M. Bausch|              9.6|\n",
      "|      Wolfgang Spier|             9.55|\n",
      "|     Beppo Schwaiger|9.533333333333333|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias('i'), \"i.name\", \"rating\").groupBy(\"i.name\").avg(\"rating\").orderBy(\"avg(rating)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22737"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\").select(\"name\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "explodedactors= movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explodedactors.filter(explodedactors[\"name\"] == \"Mickey Rooney\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "explodedactorsR= movies_df.select(explode(\"actors\").alias(\"i\"), \"i.name\", \"rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                name|      avg(rating)|\n",
      "+--------------------+-----------------+\n",
      "|      Charles Cullum|             10.0|\n",
      "|     Walter Kiaulehn|             10.0|\n",
      "|     Willem Holsboer|             10.0|\n",
      "|       John H. Moore|             10.0|\n",
      "|    Kurt Wehofschitz|              9.9|\n",
      "|    Erwin Scherschel|              9.8|\n",
      "|       Ottokar Runze|              9.8|\n",
      "|         John Wesley|              9.7|\n",
      "|        Eugen Verber|              9.7|\n",
      "|         Otto Collin|              9.6|\n",
      "|      Walter Tarrach|              9.6|\n",
      "|   Friedrich Siemers|              9.6|\n",
      "|       Allen Sferios|              9.6|\n",
      "|Hans Müller-Weste...|              9.6|\n",
      "|     Herbert Johnson|              9.6|\n",
      "|     Bernd M. Bausch|              9.6|\n",
      "|          Karl Luley|              9.6|\n",
      "|        Paul Günther|              9.6|\n",
      "|      Wolfgang Spier|             9.55|\n",
      "|     Beppo Schwaiger|9.533333333333333|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explodedactorsR.groupBy(\"i.name\").avg(\"rating\").orderBy(\"avg(rating)\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrating = movies_df.select(\"actors\", \"genres\", \"name\", movies_df[\"votes\"].cast(IntegerType()), movies_df[\"year\"].cast(IntegerType()), movies_df[\"rating\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|rating|        avg(votes)|\n",
      "+------+------------------+\n",
      "|    10|               5.5|\n",
      "|     4|124.35920889987639|\n",
      "|     3|154.43396226415095|\n",
      "|     9|165.26829268292684|\n",
      "|     2|  168.562874251497|\n",
      "|     5|176.38442840306422|\n",
      "|     6|294.60998965794613|\n",
      "|     1|            449.72|\n",
      "|     7| 763.4944402324994|\n",
      "|     8|1788.9719594594594|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intrating.groupBy(\"rating\").avg(\"votes\").orderBy(\"avg(votes)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.673361642793781"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sverge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ravge = movies_df.select(avg(\"rating\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "countbelow= movies_df.filter(movies_df[\"rating\"] > Ravge).groupby(\"genres\").count().withColumnRenamed(\"count\", \"below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "countOverall = movies_df.groupby(\"genres\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigtable = countOverall.join(countbelow.alias(\"i\"), \"genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+-------------------+\n",
      "|              genres|count|below|              ratio|\n",
      "+--------------------+-----+-----+-------------------+\n",
      "|Comedy,Horror,Sci-Fi|   18|    1|0.05555555555555555|\n",
      "|       Family,Sci-Fi|   32|    2|             0.0625|\n",
      "|Animation,Music,S...|   31|    2|0.06451612903225806|\n",
      "| Drama,Short,Western|   15|    1|0.06666666666666667|\n",
      "| Drama,History,Short|   27|    2|0.07407407407407407|\n",
      "|     Musical,Western|   13|    1|0.07692307692307693|\n",
      "| Action,Drama,Horror|   12|    1|0.08333333333333333|\n",
      "|Adventure,Fantasy...|   12|    1|0.08333333333333333|\n",
      "|Horror,Sci-Fi,Thr...|   22|    2|0.09090909090909091|\n",
      "|Action,Music,Romance|   22|    2|0.09090909090909091|\n",
      "|       Romance,Short|   42|    4|0.09523809523809523|\n",
      "|Adventure,Fantasy...|   10|    1|                0.1|\n",
      "|  Adventure,Thriller|   10|    1|                0.1|\n",
      "|     Adventure,Short|   20|    2|                0.1|\n",
      "|Action,Adventure,...|  117|   12|0.10256410256410256|\n",
      "|       Fantasy,Short|   67|    7| 0.1044776119402985|\n",
      "|     Adventure,Crime|   76|    8|0.10526315789473684|\n",
      "|       Comedy,Horror|   46|    5|0.10869565217391304|\n",
      "|  Action,Drama,Short|    9|    1| 0.1111111111111111|\n",
      "|Action,Romance,We...|   54|    6| 0.1111111111111111|\n",
      "+--------------------+-----+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigtable.withColumn(\"ratio\", bigtable[\"below\"]/bigtable[\"count\"]).orderBy(\"ratio\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise10_DF_SparkSQL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
